---
title: "F1 analysis"
author: "CORES"
date: "2025-12-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Caricamento e modifiche al dataset
```{r}
rm(list=ls())
S <-  read.csv("C:/Users/feder/Documents/datasets/Computazionale/F1/data/Telemetria_Completa_2025.csv",header = T,stringsAsFactors = T)
library(tidyverse)
S <- as_tibble(S)
levels(S$Brake) <- c(0,1)
S$Brake <- as.character(S$Brake)
S$Brake <- as.numeric(S$Brake)
S <- S %>% filter(DRS != 0)
S$DRS <- ifelse(S$DRS >11,1,0)
S_new <- S %>% select(-GP_Name,-Date,-SessionTime)
S_new$Throttle <- ifelse(S_new$Throttle > 100,100,S_new$Throttle)
S_new1 <- S_new %>% filter(Round == 1)
```
Le variabili Brake e DRS sono state reinterpretate come una dummy, nello specifico nel caso di frenata brake è pari a 1 mentre per quanto riguarda il drs la variabile DRS è pari a 1 quando è aperto

```{r}
library(scales)
S_no_l <- S_new1 %>% select(-Driver,-Round)
S_no_l_S <- S_new %>% group_by(Round) %>% mutate(across(X:Distance, ~ rescale(.,to = c(0, 1)))) %>%
  ungroup() %>% select(-Round,-Driver)

```
Normalizziamo la variabile distance ed X,Y,Z per riuscire a generalizzare per ogni tracciato 


```{r}
S_new %>% 
  group_by(Round, Driver) %>% 
  summarize(across(Speed:Distance, mean, .names = "mean_{.col}"), .groups = "drop")
```

```{r}
summary(S_no_l)
```
```{r}
diag(cov(S_no_l))
```

```{r}
corr <- cor(S_no_l)
library(ggcorrplot)
ggcorrplot(corr,hc.order = T, type="lower", lab=T)
```
Le variabili speed e Gear sono molto correlate tra di loro quindi conviene eliminare Gear che è molto meno informativa della speed
```{r}
PCA <- princomp(S_no_l %>% select(Speed,DRS,Throttle,RPM,Brake))
summary(PCA)
PCA$loadings
```

```{r}
S_pca <- S_no_l_S %>% select(-Speed,-DRS,-Throttle,-Gear)
```



```{r}
library(ggplot2)
library(GGally)
ggpairs(S_pca)
```






```{r}
library(mclust)
clust <- Mclust(S_no_l)
summary(clust)
plot(clust,what="classification",X,Y)
plot(clust,what="uncertainty")
plot(clust,what="BIC")
clust$BIC
S_no_l$cluss <- clust$classification
```


```{r}
plot(S_no_l$X,S_no_l$Y,col=S_no_l$cluss)
```

```{r}
rm(list=ls())
Se <-  read.csv("C:/Users/feder/Documents/datasets/Computazionale/F1/data/Telemetria_Completa_2025.csv",header = T,stringsAsFactors = T)
piste <- function(data,GP){
  library(tidyverse)
  S <- as_tibble(data)
  levels(S$Brake) <- c(0,1)
  S$Brake <- as.character(S$Brake)
  S$Brake <- as.numeric(S$Brake)
  S <- S %>% filter(DRS != 0)
  S$DRS <- ifelse(S$DRS >11,1,0)
  S_new <- S %>% select(-GP_Name,-Date,-SessionTime)
  S_new$Throttle <- ifelse(S_new$Throttle > 100,100,S_new$Throttle)
  S_no_l <- list()
  p <- vector()
  for (i in GP){
    S_no_l[[i]] <- S_new %>% filter(Round == i) %>% select(-Round,-Driver)
    library(mclust)
    clust <- Mclust(S_no_l[[i]])
    S_no_l[[i]]$cluss <- clust$classification
    cat(paste("Modello per Gp",i,clust$modelName,"con BIC pari a",clust$bic,"e",clust$G,"gruppi"),"\n")
  }
  n <- length(GP)
  n_cols <- ceiling(sqrt(n))       # Arrotonda per eccesso la radice quadrata
  n_rows <- ceiling(n / n_cols)    # Calcola le righe necessarie
  
  # Imposta la finestra grafica
  par(mfrow = c(n_rows, n_cols))
  for (i in GP){
    plot(S_no_l[[i]]$X,S_no_l[[i]]$Y,col=S_no_l[[i]]$cluss)}
  return(S_no_l)
 
}

res <- piste(data=Se,GP=c(1:24))
```

